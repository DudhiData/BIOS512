{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.2"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"77b97eda-a875-49d9-922a-aca98f18d1ea","cell_type":"markdown","source":"# Homework 08\nThis homework is based on the clustering lectures. Check the lecture notes and TA notes - they should help!","metadata":{}},{"id":"f75ac688-c3c4-4916-a858-97104be7e273","cell_type":"markdown","source":"## Question 1\nThis question will walk you through creating your own `kmeans` function.","metadata":{}},{"id":"9eb3eefd-fd8c-4688-8b9e-e2368e56d526","cell_type":"markdown","source":"#### a) What are the steps of `kmeans`?\n**Hint**: There are 4 steps/builder functions that you'll need.","metadata":{}},{"id":"a6b6cac6-35f2-4a71-af7f-4fbb07807b09","cell_type":"markdown","source":"1. Assign each data point to a cluster at random\n2. Calculate the mean position of each cluster using random assignment\n3. Loop through the data points and assign each one to the closest cluster center\n4. Repeat 2-3 until centers stop significant movement","metadata":{}},{"id":"bf8b199b-d1d9-4a55-ad95-9e86ad0655bd","cell_type":"markdown","source":"#### b) Create the builder function for step 1.","metadata":{}},{"id":"16bcbf06-a28c-4766-87e9-df62e2d720fe","cell_type":"code","source":"library(tidyverse)\nrandom_assign <- function(df, n_clusters) {\n    n_clusters_list <- paste0(\"C\", 1:n_clusters);\n    df$cluster <- sample(n_clusters_list, nrow(df), replace = TRUE);\n    df;\n}","metadata":{"trusted":true},"outputs":[],"execution_count":26},{"id":"9e44ddaf-4506-47d0-98fb-09871e08808c","cell_type":"markdown","source":"#### c) Create the builder function for step 2.","metadata":{}},{"id":"ea7c75b1-4fb0-4e1f-bda2-5ad7fbd7d074","cell_type":"code","source":"centers_df <- function(df) {\ndf %>% group_by(cluster) %>% summarise(across(everything(), mean), .groups = \"drop\") %>%\n  arrange(cluster)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":87},{"id":"1c8640c6-2d2f-49c3-b7ed-da0d4fb13935","cell_type":"markdown","source":"#### d) Create the builder function for step 3.\n*Hint*: There are two ways to do this part - one is significantly more efficient than the other. You can do either.  ","metadata":{}},{"id":"ab695e83-957f-4574-afa3-d271b4861b02","cell_type":"code","source":"assign_nearest_cluster <- function(df, centers) {\n    new_center <- centers %>% as.data.frame() ;\n    distances <- as.matrix(dist(rbind(voltages, new_center)));\n    dist_centers <- distances[1:nrow(df), (nrow(df) + 1):ncol(distances)]\n    apply(dist_centers, 1, which.min)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":94},{"id":"2bbea660-9bd2-4dae-9a5c-838f613b0d7c","cell_type":"markdown","source":"#### e) Create the builder function for step 4.","metadata":{}},{"id":"f0a06319-9db5-4233-b78c-0c798c7f0fd6","cell_type":"code","source":"adjusted_centers_df <- function(df_adjusted, iterations) {\n  for (i in 1:iterations) {\n      \n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":39},{"id":"f3c86f61-68d2-484a-9c9c-db7f35c8e685","cell_type":"markdown","source":"#### f) Combine them all into your own `kmeans` function.","metadata":{}},{"id":"f3209e55-561f-482f-b6f3-a0291aa05310","cell_type":"code","source":"kmeans <- function(df, n_clusters, iterations) {\n    random_assign(df, n_clusters) %>% centers_df();\n    \n}","metadata":{"trusted":true},"outputs":[],"execution_count":32},{"id":"da13180d-3a51-4218-94a0-3f362612f099","cell_type":"markdown","source":"## Question 2\nThis is when we'll test your `kmeans` function.\n#### a) Read in the `voltages_df.csv` data set. ","metadata":{}},{"id":"9f2b4213-1280-4b38-b9b7-30e81033ed5f","cell_type":"code","source":"voltages <- read_csv('voltages_df.csv')","metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"\u001b[1mRows: \u001b[22m\u001b[34m900\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m250\u001b[39m\n\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n\u001b[1mDelimiter:\u001b[22m \",\"\n\u001b[32mdbl\u001b[39m (250): 0, 1.00401606425703, 2.00803212851406, 3.01204819277108, 4.016064...\n\n\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"}],"execution_count":9},{"id":"1f002a7b-eda1-4d2d-8ef9-3090b563708d","cell_type":"markdown","source":"#### b) Call your `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$means`. ","metadata":{}},{"id":"c8644521-d6a8-44bd-9988-fa0ab7e3687f","cell_type":"code","source":" centers <- random_assign(voltages, 3) %>% centers_df();\nkmeans(voltages, 3, 50)","metadata":{"trusted":true},"outputs":[{"ename":"ERROR","evalue":"Error in rbind(deparse.level, ...): numbers of columns of arguments do not match\n","traceback":["Error in rbind(deparse.level, ...): numbers of columns of arguments do not match\nTraceback:\n","1. assign_nearest_cluster(df, centers)","2. as.matrix(dist(rbind(voltages, new_center)))","3. dist(rbind(voltages, new_center))","4. as.matrix(x)","5. rbind(voltages, new_center)","6. rbind(deparse.level, ...)","7. stop(\"numbers of columns of arguments do not match\")","8. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"numbers of columns of arguments do not match\", base::quote(rbind(deparse.level, \n .     ...)))"],"output_type":"error"}],"execution_count":93},{"id":"03d9949c-60ce-4a75-8688-e3c7485122ab","cell_type":"markdown","source":"#### c) Call R's `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$cluster`. \n*Hint*: Use the `as.matrix()` function to make the `voltages_df` data frame a matrix before calling `kmeans()`.","metadata":{}},{"id":"4944ea46-ed01-413b-8b55-d55f383413de","cell_type":"markdown","source":"#### d) Are your labels/clusters the same? If not, why? Are your means the same?","metadata":{}},{"id":"6228e5ce-269f-4d83-b94e-40f3c4a137cd","cell_type":"markdown","source":"## Question 3\n#### a) Explain the process of using a for loop to assign clusters for kmeans.","metadata":{}},{"id":"2815b679-8bd1-4ec2-85d3-e42166f3e0ff","cell_type":"markdown","source":"#### b) Explain the process of vectorizing the code to assign clusters for kmeans.","metadata":{}},{"id":"c6be7b85-c4f0-4626-b7f5-0ba921efcb6d","cell_type":"markdown","source":"#### c) State which (for loops or vectorizing) is more efficient and why.","metadata":{}},{"id":"3d2824d8-b8b6-4746-8fdc-8b3a8a1ca49d","cell_type":"markdown","source":"## Question 4\n#### When does `kmeans` fail? What assumption does `kmeans` use that causes it to fail in this situation?","metadata":{}},{"id":"20c5a711-449c-48e0-b02b-8ad3346e8d38","cell_type":"markdown","source":"## Question 5\n#### What assumption do Guassian mixture models make?","metadata":{}},{"id":"ed1a4f52-f2d5-45d7-aeb2-a05ccab9e2fe","cell_type":"markdown","source":"## Question 6\n#### What assumption does spectral clustering make? Why does this help us?","metadata":{}},{"id":"ede993cf-222f-4c5b-b09e-bc2c988a777e","cell_type":"markdown","source":"## Question 7\n#### Define the gap statistic method. What do we use it for?","metadata":{}}]}